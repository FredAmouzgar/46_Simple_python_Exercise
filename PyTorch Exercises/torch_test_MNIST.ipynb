{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_test_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHILkz5Ydycz"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision import datasets\n",
        "from tqdm import tqdm\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew9Qt_paf1Hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1306ce76-d8eb-4de1-8221-d5b2c4ade1c0"
      },
      "source": [
        "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu:0\")\n",
        "\n",
        "train_mnist = datasets.MNIST(root=\".\", download=True, train=True)\n",
        "test_mnist = datasets.MNIST(root=\".\", download=True, train=False)\n",
        "\n",
        "x_train, y_train = train_mnist.data.unsqueeze(1).to(device) / 255., train_mnist.targets.to(device)\n",
        "x_test, y_test = test_mnist.data.unsqueeze(1).to(device) / 255., test_mnist.targets.to(device)\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "\n",
        "train_size, test_size = x_train.shape[0], x_test.shape[0]\n",
        "BATCH_SIZE = 32\n",
        "TRAIN_ITER_SIZE, TEST_ITER_SIZE = train_size // BATCH_SIZE, test_size // BATCH_SIZE\n",
        "\n",
        "train_data = DataLoader(TensorDataset(x_train,y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_data = DataLoader(TensorDataset(x_test,y_test), batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "train_size, test_size, TRAIN_ITER_SIZE, TEST_ITER_SIZE"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 1, 28, 28]) torch.Size([60000]) torch.Size([10000, 1, 28, 28]) torch.Size([10000])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000, 1875, 312)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vomIEhOPYCrN",
        "outputId": "2cee9dcf-55ed-458e-8d75-4aef2445506a"
      },
      "source": [
        "batch_no = 0\n",
        "for x,y in train_data:\n",
        "  #print(x.shape, y.shape)\n",
        "  batch_no += 1\n",
        "print(\"batch_no =\", batch_no, \"\\t60000 / 32 =\", 60000 / 32)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_no = 1875 \t60000 / 32 = 1875.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKay1W_SVV0Q"
      },
      "source": [
        "# Initializing the Network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLKIGeQ_d6VI"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "    self.pooling1 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.pooling2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(in_features=128*7*7, out_features=128)\n",
        "    self.drop = nn.Dropout(0.2)\n",
        "    self.fc_out = nn.Linear(in_features=128, out_features=10)\n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pooling1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pooling2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.drop(x)\n",
        "    x = self.fc_out(x)\n",
        "    x = F.log_softmax(x, dim=-1)\n",
        "    return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5_Cpt0QVSzx"
      },
      "source": [
        "# Testing the Network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWmqj_iGfCd3",
        "outputId": "726eab07-ca24-4b40-e3b2-bea237344d5f"
      },
      "source": [
        "net = Net().to(device)\n",
        "net(torch.FloatTensor(2, 1, 28,28).normal_().to(device))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.2301, -2.2583, -2.3244, -2.3132, -2.2591, -2.3718, -2.3408, -2.3537,\n",
              "         -2.4294, -2.1710],\n",
              "        [-2.2655, -2.2716, -2.3072, -2.2975, -2.2235, -2.3447, -2.3314, -2.3489,\n",
              "         -2.4236, -2.2286]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEIxsYaQlTXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a29aa00-fe65-4786-b9be-a00577e986d5"
      },
      "source": [
        "net(x_train[0:2,...])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.2694, -2.2524, -2.2872, -2.3369, -2.2148, -2.3318, -2.3476, -2.3842,\n",
              "         -2.3777, -2.2399],\n",
              "        [-2.2701, -2.2657, -2.2987, -2.3351, -2.2231, -2.3254, -2.3417, -2.3795,\n",
              "         -2.3761, -2.2251]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTDFP8d0SsWs"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/mnist_experiment_1')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8C9WFsAUy5q",
        "outputId": "1ce1a80f-64f9-45e0-d08c-e5e005e09118"
      },
      "source": [
        "net = Net().to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optim = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "def evaluate(net, test_data, BATCH_SIZE, epoch_accuracies):\n",
        "  with torch.no_grad():\n",
        "    net.eval()\n",
        "    for x_test_batch,y_test_batch in test_data:\n",
        "      y_test_pred = net(x_test_batch)\n",
        "      accuracy = torch.sum(y_test_batch == torch.argmax(y_test_pred,dim=-1)).item()\n",
        "      epoch_accuracies.append(accuracy / BATCH_SIZE)\n",
        "      break\n",
        "\n",
        "for epoch in range(10):\n",
        "  epoch_loss = 0.0\n",
        "  epoch_accuracies = []\n",
        "  print(\"Epoch \", epoch, end=\"\")\n",
        "  for i,(x_batch,y_batch) in enumerate(train_data):\n",
        "    net.train()\n",
        "    y_pred = net(x_batch)\n",
        "    loss = criterion(y_pred, y_batch)\n",
        "    epoch_loss += loss.item()\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "      evaluate(net, test_data, BATCH_SIZE, epoch_accuracies)\n",
        "\n",
        "  print(\" | Epoch_loss: \"+str(epoch_loss)+\" | Epoch_Accuracy: \"+str(100*sum(epoch_accuracies)/len(epoch_accuracies)))\n",
        "  writer.add_scalar(\"loss\", epoch_loss, epoch)\n",
        "  writer.add_scalar(\"Accuracy\", 100*sum(epoch_accuracies)/len(epoch_accuracies), epoch)\n",
        "writer.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0 | Epoch_loss: 271.00884941924596 | Epoch_Accuracy: 96.09375\n",
            "Epoch  1 | Epoch_loss: 90.9115871508111 | Epoch_Accuracy: 98.88630319148936\n",
            "Epoch  2 | Epoch_loss: 66.83527442317427 | Epoch_Accuracy: 98.90292553191489\n",
            "Epoch  3 | Epoch_loss: 49.27120221757468 | Epoch_Accuracy: 99.13563829787235\n",
            "Epoch  4 | Epoch_loss: 44.43723610584493 | Epoch_Accuracy: 99.2686170212766\n",
            "Epoch  5 | Epoch_loss: 29.995088642527037 | Epoch_Accuracy: 99.13563829787235\n",
            "Epoch  6 | Epoch_loss: 27.822682137853917 | Epoch_Accuracy: 99.28523936170212\n",
            "Epoch  7 | Epoch_loss: 24.708456984821083 | Epoch_Accuracy: 99.20212765957447\n",
            "Epoch  8 | Epoch_loss: 20.87110854722765 | Epoch_Accuracy: 99.23537234042553\n",
            "Epoch  9 | Epoch_loss: 19.32233928172807 | Epoch_Accuracy: 99.15226063829788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjBobPg7TdMO"
      },
      "source": [
        "# Uncomment to see the plots\n",
        "#%load_ext tensorboard\n",
        "\n",
        "#%tensorboard --logdir=\"runs/\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vo8ZrV-jpq5",
        "outputId": "043d058a-4e32-4ce5-f890-cd186ae1b5ce"
      },
      "source": [
        "with torch.no_grad():\n",
        "  for x_test_batch,y_test_batch in test_data:\n",
        "    y_test_pred = net(x_test_batch)\n",
        "    accuracy = torch.sum(y_test_batch == torch.argmax(y_test_pred,dim=-1))\n",
        "    print(\"Accuracy:\", accuracy/BATCH_SIZE)\n",
        "    break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: tensor(1., device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq5pGCd0OPsH"
      },
      "source": [
        "# del model\n",
        "model = Net()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIhjC59bNfrc"
      },
      "source": [
        "torch.save(net, \"mnist_net.h5\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z01xPfANuqx"
      },
      "source": [
        "model = torch.load(\"mnist_net.h5\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIgdUPWXN_Mw",
        "outputId": "809bf77e-ce71-4c8c-ecd3-9daa0bbc3fc8"
      },
      "source": [
        "with torch.no_grad():\n",
        "  for x_test_batch,y_test_batch in test_data:\n",
        "    y_test_pred = model(x_test_batch)\n",
        "    accuracy = torch.sum(y_test_batch == torch.argmax(y_test_pred,dim=-1))\n",
        "    print(\"Accuracy:\", accuracy/BATCH_SIZE)\n",
        "    break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: tensor(0.9688, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}