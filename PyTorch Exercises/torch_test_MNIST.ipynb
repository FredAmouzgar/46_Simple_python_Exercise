{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHILkz5Ydycz"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision import datasets\n",
        "from tqdm import tqdm\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew9Qt_paf1Hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b26cc1-80fc-4652-9643-48192dee15f6"
      },
      "source": [
        "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu:0\")\n",
        "\n",
        "train_mnist = datasets.MNIST(root=\".\", download=True, train=True)\n",
        "test_mnist = datasets.MNIST(root=\".\", download=True, train=False)\n",
        "\n",
        "x_train, y_train = train_mnist.data.unsqueeze(1).to(device) / 255., train_mnist.targets.to(device)\n",
        "x_test, y_test = test_mnist.data.unsqueeze(1).to(device) / 255., test_mnist.targets.to(device)\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "\n",
        "train_size, test_size = x_train.shape[0], x_test.shape[0]\n",
        "BATCH_SIZE = 32\n",
        "TRAIN_ITER_SIZE, TEST_ITER_SIZE = train_size // BATCH_SIZE, test_size // BATCH_SIZE\n",
        "\n",
        "train_data = DataLoader(TensorDataset(x_train,y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_data = DataLoader(TensorDataset(x_test,y_test), batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "train_size, test_size, TRAIN_ITER_SIZE, TEST_ITER_SIZE"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 1, 28, 28]) torch.Size([60000]) torch.Size([10000, 1, 28, 28]) torch.Size([10000])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000, 1875, 312)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vomIEhOPYCrN",
        "outputId": "a62246f1-59ce-4036-be41-3a2ab0548170"
      },
      "source": [
        "batch_no = 0\n",
        "for x,y in train_data:\n",
        "  #print(x.shape, y.shape)\n",
        "  batch_no += 1\n",
        "print(\"batch_no =\", batch_no, \"\\t60000 / 32 =\", 60000 / 32)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_no = 1875 \t60000 / 32 = 1875.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKay1W_SVV0Q"
      },
      "source": [
        "# Initializing the Network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLKIGeQ_d6VI"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "    self.pooling1 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "    self.pooling2 = nn.MaxPool2d(kernel_size=2)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(in_features=128*7*7, out_features=128)\n",
        "    self.drop = nn.Dropout(0.2)\n",
        "    self.fc_out = nn.Linear(in_features=128, out_features=10)\n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pooling1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pooling2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.drop(x)\n",
        "    x = self.fc_out(x)\n",
        "    x = F.log_softmax(x, dim=-1)\n",
        "    return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5_Cpt0QVSzx"
      },
      "source": [
        "# Testing the Network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWmqj_iGfCd3",
        "outputId": "0eff5e0d-2bd5-4138-f73e-649be58dfaa7"
      },
      "source": [
        "net = Net().to(device)\n",
        "net(torch.FloatTensor(2, 1, 28,28).normal_().to(device))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.3185, -2.2562, -2.2732, -2.3738, -2.3899, -2.2853, -2.2469, -2.3622,\n",
              "         -2.2140, -2.3215],\n",
              "        [-2.2940, -2.2609, -2.2859, -2.3920, -2.3656, -2.2802, -2.2549, -2.3714,\n",
              "         -2.2020, -2.3355]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEIxsYaQlTXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd568be-2723-4236-cb50-16aad573ecd6"
      },
      "source": [
        "net(x_train[0:2,...])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.3114, -2.2375, -2.2805, -2.3709, -2.4043, -2.2771, -2.2639, -2.3396,\n",
              "         -2.2205, -2.3356],\n",
              "        [-2.3219, -2.2380, -2.2799, -2.3792, -2.4061, -2.2637, -2.2588, -2.3382,\n",
              "         -2.2290, -2.3272]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8C9WFsAUy5q",
        "outputId": "f6dbbb89-cc3a-4d3a-fc26-08760d364c9e"
      },
      "source": [
        "net = Net().to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optim = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "def evaluate(net, test_data, BATCH_SIZE, epoch_accuracies):\n",
        "  with torch.no_grad():\n",
        "    net.eval()\n",
        "    for x_test_batch,y_test_batch in test_data:\n",
        "      y_test_pred = net(x_test_batch)\n",
        "      accuracy = torch.sum(y_test_batch == torch.argmax(y_test_pred,dim=-1)).item()\n",
        "      epoch_accuracies.append(accuracy / BATCH_SIZE)\n",
        "      break\n",
        "\n",
        "for epoch in range(10):\n",
        "  epoch_loss = 0.0\n",
        "  epoch_accuracies = []\n",
        "  print(\"Epoch \", epoch, end=\"\")\n",
        "  for i,(x_batch,y_batch) in enumerate(train_data):\n",
        "    net.train()\n",
        "    y_pred = net(x_batch)\n",
        "    loss = criterion(y_pred, y_batch)\n",
        "    epoch_loss += loss.item()\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "      evaluate(net, test_data, BATCH_SIZE, epoch_accuracies)\n",
        "\n",
        "  print(\" | Epoch_loss: \"+str(epoch_loss)+\" | Epoch_Accuracy: \"+str(100*sum(epoch_accuracies)/len(epoch_accuracies)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0 | Epoch_loss: 264.4747666452313 | Epoch_Accuracy: 96.27659574468085\n",
            "Epoch  1 | Epoch_loss: 93.21236207432776 | Epoch_Accuracy: 98.76994680851064\n",
            "Epoch  2 | Epoch_loss: 65.56749240449062 | Epoch_Accuracy: 99.15226063829788\n",
            "Epoch  3 | Epoch_loss: 49.77416495290527 | Epoch_Accuracy: 99.20212765957447\n",
            "Epoch  4 | Epoch_loss: 39.455786682607595 | Epoch_Accuracy: 99.10239361702128\n",
            "Epoch  5 | Epoch_loss: 34.147032016590174 | Epoch_Accuracy: 99.18550531914893\n",
            "Epoch  6 | Epoch_loss: 27.92339105601087 | Epoch_Accuracy: 99.1688829787234\n",
            "Epoch  7 | Epoch_loss: 26.991504425089516 | Epoch_Accuracy: 99.00265957446808\n",
            "Epoch  8 | Epoch_loss: 22.622694585979872 | Epoch_Accuracy: 99.38497340425532\n",
            "Epoch  9 | Epoch_loss: 17.892860483425608 | Epoch_Accuracy: 99.21875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vo8ZrV-jpq5",
        "outputId": "c4ac0b39-3f64-4bb9-9780-5c5080b1e573"
      },
      "source": [
        "with torch.no_grad():\n",
        "  for x_test_batch,y_test_batch in test_data:\n",
        "    y_test_pred = net(x_test_batch)\n",
        "    accuracy = torch.sum(y_test_batch == torch.argmax(y_test_pred,dim=-1))\n",
        "    print(\"Accuracy:\", accuracy/BATCH_SIZE)\n",
        "    break"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: tensor(1., device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}